#,title,authors,date,time,"form fields",keywords,decision,notified,"reviews sent",abstract
20,"Language adapts to signal disruption in interaction","Vinicius Macuch Silva and Sean Roberts",2015-08-31,09:42,"(Type of presentation) Talk
(Submission Type) Abstract
(Student) Student
(Tweet) Interactive pressures help shape the emergence of linguistic structure","linguistic structure
interactive pressures
structural adaptation
signal disruption
conversational repair","Poster presentation",yes,yes,"Linguistic traits are often seen as reflecting cognitive biases and constraints (e.g. Christiansen & Chater, 2008). However, language must also adapt to properties of the channel through which communication between individuals occurs.  Perhaps the most basic aspect of any communication channel is noise.  Communicative signals can be blocked, degraded or distorted by other sources in the environment. This poses a fundamental problem for communication. On average, channel disruption accompanies problems in conversation every 3 minutes (27% of cases of other-initiated repair, Dingemanse et al., 2015).  Linguistic signals must adapt to this harsh environment. While modern language structures are robust to noise (e.g. Piantadosi et al., 2011), we investigate how noise might have shaped the early emergence of structure in language.
The obvious adaptation to noise is redundancy. Signals which are maximally different from competitors are harder to render ambiguous by noise.  Redundancy can be increased by adding differentiating segments to each signal (increasing the diversity of segments). However, this makes each signal more complex and harder to learn. Under this strategy, holistic languages may emerge. Another strategy is reduplication - repeating parts of the signal so that noise is less likely to disrupt all of the crucial information. This strategy does not increase the difficulty of learning the language - there is only one extra rule which applies to all signals. Therefore, under pressures for learnability, expressivity and redundancy, reduplicated signals are expected to emerge.  
However, reduplication is not a pervasive feature of words (though it does occur in limited domains like plurals or iconic meanings). We suggest that this is due to the pressure for redundancy being lifted by conversational infrastructure for repair. Receivers can request that senders repeat signals only after a problem occurs. That is, robustness is achieved by repeating the signal across conversational turns (when needed) instead of within single utterances.
As a proof of concept, we ran two iterated learning chains with pairs of individuals in generations learning and using an artificial language (e.g. Kirby et al., 2015). The meaning space was a structured collection of  unfamiliar images (3 shapes x 2 textures x 2 outline types). The initial language for each chain was the same written, unstructured, fully expressive language. Signals produced in each generation formed the training language for the next generation. Within each generation, pairs played an interactive communication game. The director was given a target meaning to describe, and typed a word for the matcher, who guessed the target meaning from a set. With a 50% probability, a contiguous section of 3-5 characters in the typed word was replaced by ‘noise’ characters (#).  In one chain, the matcher could initiate repair by requesting that the director type and send another signal. Parallel generations across chains were matched for the number of signals sent (if repair was initiated for a meaning, then it was presented twice in the parallel generation where repair was not possible) and noise (a signal for a given meaning which was affected by noise in one generation was affected by the same amount of noise in the parallel generation).  
For the final set of signals produced in each generation we measured the signal redundancy (the zip compressibility of the signals), the character diversity (entropy of the characters of the signals) and systematic structure (z-score of the correlation between signal edit distance and meaning hamming distance).  In the condition without repair, redundancy increased with each generation (r=0.97, p=0.01), and the character diversity decreased (r=-0.99,p=0.001) which is consistent with reduplication, as shown below (part of the initial and the final language):
Linear regressions revealed that generations with repair had higher overall systematic structure (main effect of condition, t = 2.5, p < 0.05), increasing character diversity (interaction between condition and generation, t = 3.9, p = 0.01) and redundancy increased at a slower rate (interaction between condition and generation, t = -2.5, p < 0.05). 
That is, the ability to repair counteracts the pressure from noise, and facilitates the emergence of compositional structure.  Therefore, just as systems to repair damage to DNA replication are vital for the evolution of biological species (O’Brien, 2006), conversational repair may regulate replication of linguistic forms in the cultural evolution of language. Future studies should further investigate how evolving linguistic structure is shaped by interaction pressures, drawing on experimental methods and naturalistic studies of emerging languages, both spoken (e.g Botha, 2006; Roberge, 2008) and signed (e.g Senghas, Kita, & Ozyurek, 2004; Sandler et al., 2005)."
86,"NONLINEAR BIASES IN ARTICULATION CONSTRAIN THE DESIGN SPACE OF LANGUAGE","Rick Janssen, Bodo Winter, Dan Dediu, Scott Moisik and Sean Roberts",2015-09-17,09:43,"(Type of presentation) Talk
(Submission Type) Abstract
(Student) Student
(Tweet) Subjects converge on stable regions in iterated learning experiment using nonlinear flutes. Anatomical biases might constrain the design space of language.","iterated learning
nonlinear biases
slide whistle experiment",accept,yes,yes,"In Iterated Learning (IL) experiments, a participant’s learned output serves as the next participant’s learning input (Kirby et al., 2014). IL can be used to model cultural transmission and has indicated that weak biases can be amplified through repeated cultural transmission (Kirby et al., 2007).  So, for example, structural language properties can emerge over time because languages come to reflect the cognitive constraints in the individuals that learn and produce the language. Similarly, we propose that languages may also reflect certain anatomical biases. Do sound systems adapt to the affordances of the articulation space induced by the vocal tract?  
The human vocal tract has inherent nonlinearities which might derive from acoustics and aerodynamics (cf. quantal theory, see Stevens, 1989) or biomechanics (cf. Gick & Moisik, 2015). For instance, moving the tongue anteriorly along the hard palate to produce a fricative does not result in large changes in acoustics in most cases, but for a small range there is an abrupt change from a perceived palato-alveolar [ʃ] to alveolar [s] sound (Perkell, 2012). Nonlinearities such as these might bias all human speakers to converge on a very limited set of phonetic categories, and might even be a basis for combinatoriality or phonemic ‘universals’.
While IL typically uses discrete symbols, Verhoef et al. (2014) have used slide whistles to produce a continuous signal. We conducted an IL experiment with human subjects who communicated using a digital slide whistle for which the degree of nonlinearity is controlled. A single parameter (α) changes the mapping from slide whistle position (the ‘articulator’) to the acoustics. With α=0, the position of the slide whistle maps Bark-linearly to the acoustics. As α approaches 1, the mapping gets more double-sigmoidal, creating three plateaus where large ranges of positions map to similar frequencies. In more abstract terms, α represents the strength of a nonlinear (anatomical) bias in the vocal tract. 
Six chains (138 participants) of dyads were tested, each chain with a different, fixed α. Participants had to communicate four meanings by producing a continuous signal using the slide-whistle in a ‘director-matcher’ game, alternating roles (cf. Garrod et al., 2007).
Results show that for high αs, subjects quickly converged on the plateaus. This quick convergence is indicative of a strong bias, repelling subjects away from unstable regions already within-subject. Furthermore, high αs lead to the emergence of signals that oscillate between two (out of three) plateaus. Because the sigmoidal spaces are spatially constrained, participants increasingly used the sequential/temporal dimension. As a result of this, the average duration of signals with high α was ~100ms longer than with low α. These oscillations could be an expression of a basis for phonemic combinatoriality.
We have shown that it is possible to manipulate the magnitude of an articulator-induced non-linear bias in a slide whistle IL framework. The results suggest that anatomical biases might indeed constrain the design space of language. In particular, the signaling systems in our study quickly converged (within-subject) on the use of stable regions. While these conclusions were drawn from experiments using slide whistles with a relatively strong bias, weaker biases could possibly be amplified over time by repeated cultural transmission, and likely lead to similar outcomes."
87,"DENDROPHOBIA IN BONOBO COMPREHENSION OF SPOKEN ENGLISH","Robert Truswell",2015-09-17,11:38,"(Type of presentation) Talk
(Submission Type) Abstract
(Student) Non-Student
(Tweet) ","Constituency
Hierarchical structure
Dendrophilia hypothesis
Bonobo",accept,yes,yes,"Fitch (2014) proposed the Dendrophilia hypothesis as a description of the ubiquity of hierarchical structures in human cognition:

‘Humans have a multi-domain capacity and proclivity to infer tree structures from strings, to a degree that is difficult or impossible for most non-human animal species.’ (Fitch, 2014, 352)

Part of Fitch’s supporting evidence concerns Fitch and Hauser’s (2004) demonstration that humans learn to recognize sequences of the forms (ab)^n and a^nb^n, while cotton-top tamarins can only learn the former. Fitch takes this to support the Dendrophilia hypothesis because (ab)^n, but not a^nb^n, can be generated in the limit by constituency-free finite-state grammars. However, this result has been disputed on empirical and theoretical grounds, e.g. Perruchet and Rey (2005), Jäger and Rogers (2012).

This paper gives a complementary source of evidence for Fitch’s hypothesis. We examine a corpus of 660 utterances directed in parallel to a bonobo, Kanzi, and a human infant, Alia, together with descriptions of their behavior in response to those utterances (Savage-Rumbaugh et al., 1993). Unlike grammar induction experiments such as Fitch and Hauser (2004), these strings are paired with interpretations. We can then infer aspects of a subject’s interpretation of an utterance from their behavior, and aspects of the grammatical representation of the utterance from that interpretation. I argue that Kanzi fails to respond to requests precisely where correct interpretation requires hierarchical constituency.

Kanzi’s overall performance across the corpus (71.5% ‘correct’ responses according to Savage-Rumbaugh et al.’s criteria) is comparable to Alia’s (66.6% ‘correct’). Usually, though, a correct response could be achieved through common-sense combination of the concepts expressed by individual words, without using syntactic information (Anderson’s 2004 semantic soup strategy). One such example, carried out correctly by Kanzi, is ""Put the backpack in the car"": few other actions involving backpacks and cars suggest themselves.

In some cases (e.g. ""Put the tomato in the oil"" / ""Put some oil in the tomato""), correct interpretation requires sensitivity to linear order, but not constituency. Kanzi’s accuracy on 43 such sentences in the corpus (21 pairs, with 1 example repeated) is 76.7%, in line with his 71.5% overall accuracy. This suggests that Kanzi can make use of linear order information in his understanding of spoken English.

However, Kanzi responded correctly to only 4/18 sentences containing coordinated NP objects (22.2%). When asked to ""Show me the milk and the doggie"", he shows only the dog; when asked to ""Give the lighter and the shoe to Rose"", he gives Rose only the lighter. Kanzi ignores the first conjunct on 9/18 trials, and ignores the second conjunct on 5/18 trials.

Despite the small number of critical sentences, this represents a highly significant drop relative to both Kanzi’s baseline accuracy (p < 10^−4) and Alia’s 68.4% accuracy on sentences containing the same construction (p < 0.01). This, then, is a species-specific, construction-specific drop in performance.

I propose that Kanzi’s performance dips precisely here (and not on many other constructions of comparable length) because correct interpretation of such sentences requires reference to hierarchical constituent structure. Specifically, unlike the previous examples, Kanzi must recognize that the object of give is the complex phrase the water and the doggie, and not just, for example, the next noun. Likewise, the patient of the action of giving should be the group of objects denoted by the complex phrase, not just the denotaton of a single noun. Kanzi’s generally impressive performance therefore only drops where reference to constituency is required, while Alia has no similar problem. In Fitch’s terms, Kanzi is more dendrophobic than Alia.

References

Anderson, S. (2004). Doctor Doolittle’s delusion. New Haven, CT: Yale University Press.
Fitch, W. T. (2014). Toward a computational framework for cognitive biology: Unifying approaches from cognitive neuoscience and comparative cognition. Physics of Life Reviews, 11, 329-364.
Fitch, W. T., & Hauser, M. (2004). Computational constraints on syntactic processing in a nonhuman primate. Science, 303, 377-380.
Jäger, G., & Rogers, J. (2012). Formal language theory: Refining the Chomsky hierarchy. Philosophical Transactions of the Royal Society B, 367, 1956- 1970.
Perruchet, P., & Rey, A. (2005). Does the mastery of center-embedded linguistic structures distinguish humans from nonhuman primates? Psychonomic Bulletin & Review, 12, 307-313.
Savage-Rumbaugh, E. S., Murphy, J., Sevcik, R., Brakke, K., Williams, S., Rumbaugh, D., & Bates, E. (1993). Language comprehension in ape and child. Monographs of the Society for Research in Child Development, 58, 1-252."
99,"Deictic Tools can Limit the Emergence of Referential Symbol Systems","Elizabeth Irvine and Sean Roberts",2015-09-17,19:49,"(Type of presentation) Talk
(Submission Type) FullPaper
(Student) Non-Student
(Tweet) Pointing & sequence organisation decreases need for symbols in co-operative tasks, symbols costly to set up so may emerge late","pointing
symbols
co-operation
gesture",accept,yes,yes,"Previous experiments and models show that the pressure to communicate can lead to the emergence of symbols in specific tasks.  The experiment presented here suggests that the ability to use deictic gestures can reduce the pressure for symbols to emerge in co-operative tasks. In the 'gesture-only' condition, pairs built a structure together in 'Minecraft', and could only communicate using a small range of gestures. In the 'gesture-plus' condition, pairs could also use sound to develop a symbol system if they wished. All pairs were taught a pointing convention. None of the pairs we tested developed a symbol system, and performance was no different across the two conditions. We therefore suggest that deictic gestures, and non-referential means of organising activity sequences, are often sufficient for communication. This suggests that the emergence of linguistic symbols in early hominids may have been late and patchy with symbols only emerging in contexts where they could significantly improve task success or efficiency. Given the communicative power of pointing however, these contexts may be fewer than usually supposed. An approach for identifying these situations is outlined."